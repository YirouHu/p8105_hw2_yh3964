---
title: "p8105_hw2_yh3964"
author: "Yirou Hu"
date: "2025-09-26"
output: github_document
---
# Problem 0
We import the datasets and create all the required files with name. 
```{r}
library(tidyverse)
library(readxl)
```

# Problem 1
We will do data cleaning for pols-month.csv firstly. 

- break up the variable mon into integer variables year, month, and day; 
- replace month number with month name; 
- create a president variable taking values gop and dem, 
- remove prez_dem and prez_gop
- remove the day variable.

```{r}
pols_month = read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    month = case_match(
      month, 
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec")
  )|>
  mutate(
    president=case_match(
      prez_gop,
    0~"dem",
    1~"gop",
    2~"gop"
    )
  )|>
  mutate(year = as.integer(year), day = as.integer(day)) |>
  select(-c("day", "prez_gop", "prez_dem"))
```

Second, clean the data in snp.csv
- arrange according to year and month.
- organize so that year and month are the leading columns.

```{r}
snp = read.csv("fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), sep = "/" ) |>
  mutate(month = as.integer(month), year = as.integer(year)) |>
  arrange(year, month) |>
  mutate(
    month = case_match(
      month,
      1 ~ "Jan",
      2 ~ "Feb",
      3 ~ "Mar",
      4 ~ "Apr",
      5 ~ "May",
      6 ~ "Jun",
      7 ~ "Jul",
      8 ~ "Aug",
      9 ~ "Sep",
      10 ~ "Oct",
      11 ~ "Nov",
      12 ~ "Dec"
    )) |>
  relocate(year, month) |>
  select(-"day")

```

Third, tidy the unemployment data so that it can be merged with the previous datasets.

- This process will involve switching from “wide” to “long” format; 
- ensuring that key variables have the same name; 
- and ensuring that key variables take the same values.

```{r}
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month",
    values_to = "unemployment"
  ) 
  
```

```{r}
Joint_df = 
  left_join(
  x = left_join(pols_month,snp, by = c("year", "month")), 
  y = unemployment, by = c("year", "month")
  )
```

It’s important to note that the close and unemployment variables contain some NA values, which mean the corresponding values are missing at those positions.

In detail:

- The pols data has `r nrow(pols_month)` observations and `r ncol(pols_month)` variables. It records the party affiliation for each year from 1947 to 2015.
- The snp data has `r nrow(snp)` observations and `r ncol(snp)` variables, covering years from `r range(snp$year)[1]` to `r range(snp$year)[2]`, and it contains information related to the S&P stock market index.
- The unemployment data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables, spanning `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`, and it tracks monthly unemployment rates.
- The pols_month dataset is a simplified version focusing on the president’s party affiliation. It has `r nrow(pols_month)` rows and `r ncol(pols_month)` columns, with years ranging from `r range(pols_month$year)[1]` to `r range(pols_month$year)[2]`.
- The merged Joint_df dataset combines pols_month, snp, and unemployment. It has `r nrow(Joint_df)` rows and `r ncol(Joint_df)` columns, covering years from `r range(Joint_df$year)[1]` to `r range(Joint_df$year)[2]`.

In addition, we can compare the average unemployment value in a random year with two party affiliations. For Decembers after 2002, the average unemployment rate when a Democrat was president was `r filter(Joint_df, month == "Dec", year >= 2002, president == "dem") |> pull(unemployment) |> mean()`. Furthermore, the average unemployment rate when a Republican was president was `r filter(Joint_df, month == "Dec", year >= 2002, president == "gop") |> pull(unemployment) |> mean()`. 


# Problem 2

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
#readxl::read_excel("202409 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range ="A2:N586", na = c("NA", "", ".")) |>
mr_trash_wheel_df =
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(
    year = as.integer(year),
    homes_powered = weight_tons*500/30,
    sports_balls = as.integer(round(sports_balls)), 
    trash_wheel = "Mr. Trash Wheel",
    ) |> 
  drop_na(dumpster)
```

Read and clean Professor Trash Wheel dataset

```{r}
professor_trash_wheel_df = 
  #read_excel("202409 Trash Wheel Collection Data.xlsx", 
  #           sheet = "Professor Trash Wheel",
  #          range = "A2:M120",
  #           na = c("NA", "", ".")) |> 
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M120"
             ) |>
  janitor::clean_names() |> 
  mutate(
    trash_wheel = "Professor", 
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    ) |> 
  select(-dumpster)
```

Read and clean Gwynnda dataset

```{r}
gwynnda_trash_wheel_df = 
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L265",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |>
  mutate(
    trash_wheel = "Gwynnda",
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    )
```

Combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset.

```{r}
trash_wheel_whole_df = bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |>
relocate(trash_wheel)
```

Write a paragraph about these data
- you are encouraged to use inline R.
- Be sure to note the number of observations in the resulting dataset, and give examples of key variables. 
- For available data, what was the total weight of trash collected by Professor Trash Wheel? 
- What was the total number of cigarette butts collected by Gwynnda in June of 2022?


- `mr_trash_wheel_df` contains `r nrow(mr_trash_wheel_df)` rows and `r ncol(mr_trash_wheel_df)` columns of data.
- `professor_trash_wheel_df` contains `r nrow(professor_trash_wheel_df)` rows and `r ncol(professor_trash_wheel_df)` columns of data.
- `gwynnda_trash_wheel_df` contains `r nrow(gwynnda_trash_wheel_df)` rows and `r ncol(gwynnda_trash_wheel_df)` columns of data.
- The final data set `trash_wheel_whole_df` contains `r nrow(trash_wheel_whole_df)` rows and `r ncol(trash_wheel_whole_df)` columns of data. The variables are `r names(trash_wheel_whole_df)`.
- The total weight of trash collected by Professor Trash Wheel is `r sum(professor_trash_wheel_df$weight_tons)`.
- The total number of cigarette butts collected by Gwynnda in June of 2022 is `r as.integer(sum(gwynnda_trash_wheel_df$cigarette_butts[which(gwynnda_trash_wheel_df$month == "June" & gwynnda_trash_wheel_df$year == 2022)]))`.


# Problem 3

Zillow Observed Rent Index (ZORI) in New York City between January 2015 and August 2024.

Firstsly ,we load the dataset.
```{r load dataset}
zip_codes_df = read_csv("zillow_data/Zip Codes.csv")
zori_df = read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

- create a single, well-organized dataset with all the information contained in these data files. 
- To that end: import, clean, tidy, and otherwise wrangle each of these datasets
- check for completeness and correctness across datasets (e.g. by viewing individual datasets and monitoring warning messages).
- merge to create a single, final dataset
- organize this so that variables and observations are in meaningful orders.

We first do data cleaning about zip code datasets.
```{r}
zip_codes_df = 
  read_csv("zillow_data/Zip Codes.csv") |>
  rename(
    county = County,
    state_fips = "State FIPS",
    county_code = "County Code",
    county_fips = "County FIPS",
    zip_code = ZipCode,
    file_date = "File Date",
    neighborhood = Neighborhood
  ) |>
  drop_na(neighborhood) |>
  filter(neighborhood != "NA") |>
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y"))
```


Next, we do data cleaning on zillow rent price dataset.
```{r}
zillow_rent_df = 
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  rename(
     zip_code = "RegionName",
     region_id = "RegionID",
     size_rank = "SizeRank",
     region_type = "RegionType",
     state_name = "StateName",
     state = "State",
     city = "City",
     metro = "Metro",
     county_name = "CountyName"
  ) |>
  select(zip_code, everything()) |>
  pivot_longer(
    cols = starts_with("20"),
    names_to = "date",
    values_to = "rent"
  ) |>
  drop_na(rent)
  
```

Moreover, we merge them together by using left join methods and drop unimportant and repeated variables.

```{r}
merged_data_df = 
  left_join(zillow_rent_df, zip_codes_df, by = "zip_code") |>
  select(-county, -state) |>
  relocate(zip_code, county_name, neighborhood, rent)
```

We will use two ways to check the the ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset.

Possible reasons for exclusion from Zillow:

- Low population density or limited rental activity: Many of the missing ZIP codes correspond to areas with smaller populations or fewer rental units like Rockaways. Zillow may not have enough transactions to generate reliable rental price estimates.

- Non-residential areas: Some ZIP codes may contain industrial zones, commercial areas, parks, or other non-residential regions, where typical rental data is unavailable.

- Data privacy : Zillow might exclude ZIP codes with very few rental listings to protect the privacy of landlords and tenants, or to avoid publishing unreliable estimates.


Take an example of ZIP code 10464, which is absent from Zillow's rental dataset. It may due to insufficient rental listings or low market activity in that area. Furthermore, the region Rockaways we mention aboved is absent from Zillow due to small populations.

```{r}
difference_in_zipcodes_df = 
  anti_join(zip_codes_df, zillow_rent_df)
difference_in_zipcodes_df
```

```{r}
zip_not_in_zillow =
  zip_codes_df |>
  filter(!zip_code %in% zillow_rent_df$zip_code)
zip_not_in_zillow
```

The result shows the same output.

- Briefly describe the resulting tidy dataset. 
- How many total observations exist? How many unique ZIP codes are included
- How many unique neighborhoods

The resulting tidy dataset `merged_data_df` combines information from the Zillow rental price dataset and the ZIP code dataset for New York City. It is organized in a long format, where each row represents the observed rent for a given ZIP code, neighborhood, and month.

- The dataset contains a total of `r nrow(merged_data_df)` observations.  
- There are `r n_distinct(merged_data_df$zip_code)` unique ZIP codes included.  
- The dataset covers `r n_distinct(merged_data_df$neighborhood)` unique neighborhoods across all boroughs.
- Date range of the rent observations: from `r min(merged_data_df$month)` to `r max(merged_data_df$month)` 

Each observation includes the following variables:

- `zip_code`: the ZIP code of the area  
- `county_name`: the county name corresponding to the ZIP code  
- `neighborhood`: the neighborhood name associated with the ZIP code  
- `month`: the month of the rent observation  
- `rent`: the Zillow Observed Rent Index (ZORI) for the corresponding month and ZIP code

Missing values in `rent` or `neighborhood` have been removed to ensure completeness. The variables are organized in a meaningful order, with `zip_code`, `county_name`, and `neighborhood` first, followed by rent and month information.


Rental prices fluctuated dramatically during the COVID-19 pandemic. 
- For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. 
- Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021.
- Comment.


First, we filtered data from merged_data_df to include only January 2020 and January 2021 records, extracting key variables: ZIP code, borough (county), neighborhood, year, and rent. We then removed duplicate entries to ensure each combination had one unique rent value.

Next, we restructured the data to have separate columns for 2020 and 2021 rents, calculated the price change (drop_price = 2021 rent - 2020 rent), and removed entries with missing data.

```{r}
rent_jan = 
  merged_data_df |>
  mutate(
    date = as.Date(date, format = "%Y-%m-%d"),
    year = year(date),
    month = month(date),
    day = day(date)
    ) |>
  filter(month == 1 & (year == 2020 | year == 2021)) |>
  select(zip_code, county_name, neighborhood, year, rent)
```

```{r}
rent_diff = 
  rent_jan |>
  distinct() |>
  pivot_wider(
    id_cols = c(zip_code, county_name, neighborhood), 
    names_from = year,                                 
    values_from = rent,                                
    names_prefix = "rent_") |>
  mutate(drop_price = rent_2021 - rent_2020) |>
  drop_na() |>
  select(county_name, zip_code, neighborhood, drop_price)
```

We create a table about top 10 drop with appropriate caption names
```{r}
top10_drop =
  rent_diff |>
  arrange(drop_price) |>
  slice_head(n = 10) |>
  rename(
    "Borough" = county_name,      
    "ZIP Code" = zip_code,        
    "Neighborhood" = neighborhood, 
    "Price Drop (2020-2021)" = drop_price  
  )

```

```{r}
knitr::kable(
  top10_drop,
  caption = "Top 10 largest drop in price from January 2020 to 2021",
  align = "lccc"  
)
```
