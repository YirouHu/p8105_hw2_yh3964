---
title: "p8105_hw2_yh3964"
author: "Yirou Hu"
date: "2025-09-26"
output: github_document
---
# Problem 0
We import the datasets and create all the required files with name. 
```{r}
library(tidyverse)
library(readxl)
```

# Problem 1
We will do data cleaning for pols-month.csv firstly. 

- break up the variable mon into integer variables year, month, and day; 
- replace month number with month name; 
- create a president variable taking values gop and dem, 
- remove prez_dem and prez_gop
- remove the day variable.

```{r}
pols_month = read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), convert = TRUE) |>
  mutate(
    month = month.name[as.numeric(month)],
    year = as.character(year),
    president = 
      case_match(
      prez_gop,
        1 ~ "gop",
      ),
    president =
      case_match(
        prez_dem,
        1 ~ "dem"
      )
    ) |>
  select(-c("day", "prez_gop", "prez_dem"))
```

Second, clean the data in snp.csv
- arrange according to year and month.
- organize so that year and month are the leading columns.

```{r}
snp = 
  read.csv("fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names() |>
  mutate(
    date = as.Date(date, format = "%m/%d/%y")
  ) |>
  separate(date, into = c("year", "month", "day"), convert = TRUE ) |>
  mutate(
    month = month.name[as.numeric(month)],
    year = as.character(year)
  ) |>
  arrange(year,month)|>
  select(-day)
```

Third, tidy the unemployment data so that it can be merged with the previous datasets.

- This process will involve switching from “wide” to “long” format; 
- ensuring that key variables have the same name; 
- and ensuring that key variables take the same values.

```{r}
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month",
    values_to = "unemployment"
  ) |>
  drop_na() |>
  mutate(year = as.character(year))
  
```

We firstly merge pols_month with snp.
Next, we merger Joint_df_pol_snp with unemployment data

```{r}
Joint_df_pol_snp_unemploy =
  left_join(
    x = left_join(pols_month,snp, by = c("year", "month")), 
    y = unemployment, 
    by = c("year", "month")
    )
```

It’s important to note that the close and unemployment variables contain some NA values, which mean the corresponding values are missing at those positions.

In detail:

- The pols data has `r nrow(pols_month)` observations and `r ncol(pols_month)` variables. It records the party affiliation for each year from 1947 to 2015.
- The snp data has `r nrow(snp)` observations and `r ncol(snp)` variables, covering years from `r range(snp$year)[1]` to `r range(snp$year)[2]`, and it contains information related to the S&P stock market index.
- The unemployment data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables, spanning `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`, and it tracks monthly unemployment rates.
- The pols_month dataset is a simplified version focusing on the president’s party affiliation. It has `r nrow(pols_month)` rows and `r ncol(pols_month)` columns, with years ranging from `r range(pols_month$year)[1]` to `r range(pols_month$year)[2]`.
- The merged Joint_df_pol_snp_unemploy dataset combines pols_month, snp, and unemployment. It has `r nrow(Joint_df_pol_snp_unemploy)` rows and `r ncol(Joint_df_pol_snp_unemploy)` columns, covering years from `r range(Joint_df_pol_snp_unemploy$year)[1]` to `r range(Joint_df_pol_snp_unemploy$year)[2]`.

# Problem 2

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- round the number of sports balls to the nearest integer and converts the result to an integer variable (using as.integer)

```{r}
mr_trash_wheel_df =
  readxl::read_excel("202509 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range = "A2:N709") |>
  janitor::clean_names() |>
  mutate(
    year = as.integer(year),
    homes_powered = weight_tons*500/30,
    sports_balls = as.integer(round(sports_balls)), 
    trash_wheel = "Mr. Trash Wheel",
    ) |> 
  drop_na(dumpster)
```

Read and clean Professor Trash Wheel dataset

```{r}
professor_trash_wheel_df = 
  readxl::read_excel("202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M134"
             ) |>
  janitor::clean_names() |> 
  drop_na(dumpster) |>
  mutate(
    trash_wheel = "Professor", 
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    ) 
```

Read and clean Gwynnda dataset

```{r}
gwynnda_trash_wheel_df = 
  readxl::read_excel("202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynns Falls Trash Wheel",
             range = "A2:L351",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |>
  mutate(
    trash_wheel = "Gwynnda",
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    )
```

Combine this with the Mr. Trash Wheel dataset to produce a single tidy dataset.

```{r}
trash_wheel_whole_df = bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |>
relocate(trash_wheel)
```

Write a paragraph about these data
- you are encouraged to use inline R.
- Be sure to note the number of observations in the resulting dataset, and give examples of key variables. 
- For available data, what was the total weight of trash collected by Professor Trash Wheel? 
- What was the total number of cigarette butts collected by Gwynnda in June of 2022?


- `mr_trash_wheel_df` contains `r nrow(mr_trash_wheel_df)` rows and `r ncol(mr_trash_wheel_df)` columns of data.
- `professor_trash_wheel_df` contains `r nrow(professor_trash_wheel_df)` rows and `r ncol(professor_trash_wheel_df)` columns of data.
- `gwynnda_trash_wheel_df` contains `r nrow(gwynnda_trash_wheel_df)` rows and `r ncol(gwynnda_trash_wheel_df)` columns of data.
- The final data set `trash_wheel_whole_df` contains `r nrow(trash_wheel_whole_df)` rows and `r ncol(trash_wheel_whole_df)` columns of data. The variables are `r names(trash_wheel_whole_df)`.
- The total weight of trash collected by Professor Trash Wheel is `r sum(professor_trash_wheel_df$weight_tons)`.
- The total number of cigarette butts collected by Gwynnda in June of 2022 is `r as.integer(sum(gwynnda_trash_wheel_df$cigarette_butts[which(gwynnda_trash_wheel_df$month == "June" & gwynnda_trash_wheel_df$year == 2022)]))`.


# Problem 3

Zillow Observed Rent Index (ZORI) in New York City between January 2015 and August 2024.

Firstsly ,we load the dataset.
```{r load dataset}
zip_codes_df = read_csv("zillow_data/Zip Codes.csv")
zori_df = read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

- create a single, well-organized dataset with all the information contained in these data files. 
- To that end: import, clean, tidy, and otherwise wrangle each of these datasets
- check for completeness and correctness across datasets (e.g. by viewing individual datasets and monitoring warning messages).
- merge to create a single, final dataset
- organize this so that variables and observations are in meaningful orders.

We first do data cleaning about zip code datasets.
```{r}
zip_codes_df = 
  read_csv("zillow_data/Zip Codes.csv") |>
  rename(
    county = County,
    state_fips = "State FIPS",
    county_code = "County Code",
    county_fips = "County FIPS",
    zip_code = ZipCode,
    file_date = "File Date",
    neighborhood = Neighborhood
  ) |>
  drop_na(neighborhood) |>
  filter(neighborhood != "NA") |>
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y"))
```


Next, we do data cleaning on zillow rent price dataset.
```{r}
zillow_rent_df = 
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  rename(
     zip_code = "RegionName",
     region_id = "RegionID",
     size_rank = "SizeRank",
     region_type = "RegionType",
     state_name = "StateName",
     state = "State",
     city = "City",
     metro = "Metro",
     county_name = "CountyName"
  ) |>
  select(zip_code, everything()) |>
  pivot_longer(
    cols = starts_with("20"),
    names_to = "date",
    values_to = "rent"
  ) |>
  drop_na(rent)
  
```

Moreover, we merge them together by using left join methods and drop unimportant and repeated variables.

```{r}
merged_data_df = 
  left_join(zillow_rent_df, zip_codes_df, by = "zip_code") |>
  select(-county, -state) |>
  relocate(zip_code, county_name, neighborhood, rent)
```

We will use two ways to check the the ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset.

Possible reasons for exclusion from Zillow:

- Low population density or limited rental activity: Many of the missing ZIP codes correspond to areas with smaller populations or fewer rental units like Rockaways. Zillow may not have enough transactions to generate reliable rental price estimates.

- Non-residential areas: Some ZIP codes may contain industrial zones, commercial areas, parks, or other non-residential regions, where typical rental data is unavailable.

- Data privacy : Zillow might exclude ZIP codes with very few rental listings to protect the privacy of landlords and tenants, or to avoid publishing unreliable estimates.


Take an example of ZIP code 10464, which is absent from Zillow's rental dataset. It may due to insufficient rental listings or low market activity in that area. Furthermore, the region Rockaways we mention aboved is absent from Zillow due to small populations.

```{r}
difference_in_zipcodes_df = 
  anti_join(zip_codes_df, zillow_rent_df)
difference_in_zipcodes_df
```

```{r}
zip_not_in_zillow =
  zip_codes_df |>
  filter(!zip_code %in% zillow_rent_df$zip_code)
zip_not_in_zillow
```

The result shows the same output.

- Briefly describe the resulting tidy dataset. 
- How many total observations exist? How many unique ZIP codes are included
- How many unique neighborhoods

The resulting tidy dataset `merged_data_df` combines information from the Zillow rental price dataset and the ZIP code dataset for New York City. It is organized in a long format, where each row represents the observed rent for a given ZIP code, neighborhood, and month.

- The dataset contains a total of `r nrow(merged_data_df)` observations.  
- There are `r n_distinct(merged_data_df$zip_code)` unique ZIP codes included.  
- The dataset covers `r n_distinct(merged_data_df$neighborhood)` unique neighborhoods across all boroughs.
- Date range of the rent observations: from `r min(merged_data_df$date)` to `r max(merged_data_df$date)` 

Each observation includes the following variables:

- `zip_code`: the ZIP code of the area  
- `county_name`: the county name corresponding to the ZIP code  
- `neighborhood`: the neighborhood name associated with the ZIP code  
- `date`: the date of the rent observation  
- `rent`: the Zillow Observed Rent Index (ZORI) for the corresponding month and ZIP code

Missing values in `rent` or `neighborhood` have been removed to ensure completeness. The variables are organized in a meaningful order, with `zip_code`, `county_name`, and `neighborhood` first, followed by rent and month information.


Rental prices fluctuated dramatically during the COVID-19 pandemic. 
- For all available ZIP codes, compare rental prices in January 2021 to prices in January 2020. 
- Make a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021.
- Comment.


First, we filtered data from merged_data_df to include only January 2020 and January 2021 records, extracting key variables: ZIP code, borough (county), neighborhood, year, and rent. We then removed duplicate entries to ensure each combination had one unique rent value.

Next, we restructured the data to have separate columns for 2020 and 2021 rents, calculated the price change (drop_price = 2021 rent - 2020 rent), and removed entries with missing data.

```{r}
rent_jan = 
  merged_data_df |>
  mutate(
    date = as.Date(date, format = "%Y-%m-%d"),
    year = year(date),
    month = month(date),
    day = day(date)
    ) |>
  filter(month == 1 & (year == 2020 | year == 2021)) |>
  select(zip_code, county_name, neighborhood, year, rent)
```

```{r}
rent_diff = 
  rent_jan |>
  distinct() |>
  pivot_wider(
    id_cols = c(zip_code, county_name, neighborhood), 
    names_from = year,                                 
    values_from = rent,                                
    names_prefix = "rent_") |>
  mutate(drop_price = rent_2021 - rent_2020) |>
  drop_na() |>
  select(county_name, zip_code, neighborhood, drop_price)
```

We create a table about top 10 drop with appropriate caption names
```{r}
top10_drop =
  rent_diff |>
  arrange(drop_price) |>
  slice_head(n = 10) |>
  rename(
    "Borough" = county_name,      
    "ZIP Code" = zip_code,        
    "Neighborhood" = neighborhood, 
    "Price Drop (2020-2021)" = drop_price  
  )

```

```{r}
knitr::kable(
  top10_drop,
  caption = "Top 10 largest drop in price from January 2020 to 2021",
  align = "lccc"  
)
```

Comments:

The table shows that all listed ZIP codes in New York County saw a significant drop in rental prices from January 2020 to January 2021, with decreases between about $672 and $913. The biggest decline happened in Lower Manhattan (ZIP 10007), which indicates the strong effect of the COVID-19 pandemic on this sought-after area.

All the affected ZIP codes are in Manhattan, including neighborhoods like Lower East Side, Gramercy Park, Chelsea, and Lower Manhattan itself. These central, high-rent areas usually attract a lot of residential and commercial interest, making them especially vulnerable to changes in population movement and economic activity.

The declines likely come from lower demand due to remote work, people moving away, and less short-term rental activity during the pandemic. This data shows that Manhattan’s main rental market was hit hardest, offering valuable insights for investors, property managers, and policymakers looking at the short-term impacts of the pandemic on urban housing markets.