p8105_hw2_yh3964
================
Yirou Hu
2025-09-26

# Problem 0

We import the datasets and create all the required files with name.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

We will do data cleaning for pols-month.csv firstly.

- break up the variable mon into integer variables year, month, and day;
- replace month number with month name;
- create a president variable taking values gop and dem,
- remove prez_dem and prez_gop
- remove the day variable.

``` r
pols_month = read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    month = case_match(
      month, 
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec")
  )|>
  mutate(
    president=case_match(
      prez_gop,
    0~"dem",
    1~"gop",
    2~"gop"
    )
  )|>
  mutate(year = as.integer(year), day = as.integer(day)) |>
  select(-c("day", "prez_gop", "prez_dem"))
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Second, clean the data in snp.csv - arrange according to year and
month. - organize so that year and month are the leading columns.

``` r
snp = read.csv("fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), sep = "/" ) |>
  mutate(month = as.integer(month), year = as.integer(year)) |>
  arrange(year, month) |>
  mutate(
    month = case_match(
      month,
      1 ~ "Jan",
      2 ~ "Feb",
      3 ~ "Mar",
      4 ~ "Apr",
      5 ~ "May",
      6 ~ "Jun",
      7 ~ "Jul",
      8 ~ "Aug",
      9 ~ "Sep",
      10 ~ "Oct",
      11 ~ "Nov",
      12 ~ "Dec"
    )) |>
  relocate(year, month) |>
  select(-"day")
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets.

- This process will involve switching from “wide” to “long” format;
- ensuring that key variables have the same name;
- and ensuring that key variables take the same values.

``` r
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month",
    values_to = "unemployment"
  ) 
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
Joint_df = 
  left_join(
  x = left_join(pols_month,snp, by = c("year", "month")), 
  y = unemployment, by = c("year", "month")
  )
```

It’s important to note that the close and unemployment variables contain
some NA values, which mean the corresponding values are missing at those
positions.

In detail:

- The pols data has 822 observations and 9 variables. It records the
  party affiliation for each year from 1947 to 2015.
- The snp data has 787 observations and 3 variables, covering years from
  0 to 99, and it contains information related to the S&P stock market
  index.
- The unemployment data has 816 observations and 3 variables, spanning
  1948 to 2015, and it tracks monthly unemployment rates.
- The pols_month dataset is a simplified version focusing on the
  president’s party affiliation. It has 822 rows and 9 columns, with
  years ranging from 1947 to 2015.
- The merged Joint_df dataset combines pols_month, snp, and
  unemployment. It has 822 rows and 11 columns, covering years from 1947
  to 2015.

In addition, we can compare the average unemployment value in a random
year with two party affiliations. For Decembers after 2002, the average
unemployment rate when a Democrat was president was 7.9833333.
Furthermore, the average unemployment rate when a Republican was
president was 5.5285714.

# Problem 2

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- round the number of sports balls to the nearest integer and converts
  the result to an integer variable (using as.integer)

``` r
#readxl::read_excel("202409 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range ="A2:N586", na = c("NA", "", ".")) |>
mr_trash_wheel_df =
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range ="A2:N586") |>
  janitor::clean_names() |>
  mutate(
    year = as.integer(year),
    homes_powered = weight_tons*500/30,
    sports_balls = as.integer(round(sports_balls)), 
    trash_wheel = "Mr. Trash Wheel",
    ) |> 
  drop_na(dumpster)
```

Read and clean Professor Trash Wheel dataset

``` r
professor_trash_wheel_df = 
  #read_excel("202409 Trash Wheel Collection Data.xlsx", 
  #           sheet = "Professor Trash Wheel",
  #          range = "A2:M120",
  #           na = c("NA", "", ".")) |> 
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M120"
             ) |>
  janitor::clean_names() |> 
  mutate(
    trash_wheel = "Professor", 
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    ) |> 
  select(-dumpster)
```

Read and clean Gwynnda dataset

``` r
gwynnda_trash_wheel_df = 
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L265",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |>
  mutate(
    trash_wheel = "Gwynnda",
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    )
```

Combine this with the Mr. Trash Wheel dataset to produce a single tidy
dataset.

``` r
trash_wheel_whole_df = bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |>
relocate(trash_wheel)
```

Write a paragraph about these data - you are encouraged to use inline
R. - Be sure to note the number of observations in the resulting
dataset, and give examples of key variables. - For available data, what
was the total weight of trash collected by Professor Trash Wheel? - What
was the total number of cigarette butts collected by Gwynnda in June of
2022?

- `mr_trash_wheel_df` contains 584 rows and 15 columns of data.
- `professor_trash_wheel_df` contains 118 rows and 13 columns of data.
- `gwynnda_trash_wheel_df` contains 263 rows and 13 columns of data.
- The final data set `trash_wheel_whole_df` contains 965 rows and 15
  columns of data. The variables are trash_wheel, dumpster, month, year,
  date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
  cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls,
  homes_powered.
- The total weight of trash collected by Professor Trash Wheel is
  246.74.
- The total number of cigarette butts collected by Gwynnda in June of
  2022 is 18120.

# Problem 3

Zillow Observed Rent Index (ZORI) in New York City between January 2015
and August 2024.

Firstsly ,we load the dataset.

``` r
zip_codes_df = read_csv("zillow_data/Zip Codes.csv")
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zori_df = read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

- create a single, well-organized dataset with all the information
  contained in these data files.
- To that end: import, clean, tidy, and otherwise wrangle each of these
  datasets
- check for completeness and correctness across datasets (e.g. by
  viewing individual datasets and monitoring warning messages).
- merge to create a single, final dataset
- organize this so that variables and observations are in meaningful
  orders.

We first do data cleaning about zip code datasets.

``` r
zip_codes_df = 
  read_csv("zillow_data/Zip Codes.csv") |>
  rename(
    county = County,
    state_fips = "State FIPS",
    county_code = "County Code",
    county_fips = "County FIPS",
    zip_code = ZipCode,
    file_date = "File Date",
    neighborhood = Neighborhood
  ) |>
  drop_na(neighborhood) |>
  filter(neighborhood != "NA") |>
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y"))
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Next, we do data cleaning on zillow rent price dataset.

``` r
zillow_rent_df = 
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  rename(
     zip_code = "RegionName",
     region_id = "RegionID",
     size_rank = "SizeRank",
     region_type = "RegionType",
     state_name = "StateName",
     state = "State",
     city = "City",
     metro = "Metro",
     county_name = "CountyName"
  ) |>
  select(zip_code, everything()) |>
  pivot_longer(
    cols = starts_with("20"),
    names_to = "month",
    values_to = "rent"
  ) |>
  drop_na(rent)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
