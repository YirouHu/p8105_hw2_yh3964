p8105_hw2_yh3964
================
Yirou Hu
2025-09-26

# Problem 0

We import the datasets and create all the required files with name.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

# Problem 1

We will do data cleaning for pols-month.csv firstly.

- break up the variable mon into integer variables year, month, and day;
- replace month number with month name;
- create a president variable taking values gop and dem,
- remove prez_dem and prez_gop
- remove the day variable.

``` r
pols_month = read_csv("fivethirtyeight_datasets/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    month = case_match(
      month, 
    "01"~"Jan",
    "02"~"Feb",
    "03"~"Mar",
    "04"~"Apr",
    "05"~"May",
    "06"~"Jun",
    "07"~"Jul",
    "08"~"Aug",
    "09"~"Sep",
    "10"~"Oct",
    "11"~"Nov",
    "12"~"Dec")
  )|>
  mutate(
    president=case_match(
      prez_gop,
    0~"dem",
    1~"gop",
    2~"gop"
    )
  )|>
  mutate(year = as.integer(year), day = as.integer(day)) |>
  select(-c("day", "prez_gop", "prez_dem"))
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Second, clean the data in snp.csv - arrange according to year and
month. - organize so that year and month are the leading columns.

``` r
snp = read.csv("fivethirtyeight_datasets/snp.csv") |>
  janitor::clean_names() |>
  separate(date, into = c("month", "day", "year"), sep = "/" ) |>
  mutate(month = as.integer(month), year = as.integer(year)) |>
  arrange(year, month) |>
  mutate(
    month = case_match(
      month,
      1 ~ "Jan",
      2 ~ "Feb",
      3 ~ "Mar",
      4 ~ "Apr",
      5 ~ "May",
      6 ~ "Jun",
      7 ~ "Jul",
      8 ~ "Aug",
      9 ~ "Sep",
      10 ~ "Oct",
      11 ~ "Nov",
      12 ~ "Dec"
    )) |>
  relocate(year, month) |>
  select(-"day")
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets.

- This process will involve switching from “wide” to “long” format;
- ensuring that key variables have the same name;
- and ensuring that key variables take the same values.

``` r
unemployment = 
  read_csv("fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month",
    values_to = "unemployment"
  ) 
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
Joint_df = 
  left_join(
  x = left_join(pols_month,snp, by = c("year", "month")), 
  y = unemployment, by = c("year", "month")
  )
```

It’s important to note that the close and unemployment variables contain
some NA values, which mean the corresponding values are missing at those
positions.

In detail:

- The pols data has 822 observations and 9 variables. It records the
  party affiliation for each year from 1947 to 2015.
- The snp data has 787 observations and 3 variables, covering years from
  0 to 99, and it contains information related to the S&P stock market
  index.
- The unemployment data has 816 observations and 3 variables, spanning
  1948 to 2015, and it tracks monthly unemployment rates.
- The pols_month dataset is a simplified version focusing on the
  president’s party affiliation. It has 822 rows and 9 columns, with
  years ranging from 1947 to 2015.
- The merged Joint_df dataset combines pols_month, snp, and
  unemployment. It has 822 rows and 11 columns, covering years from 1947
  to 2015.

In addition, we can compare the average unemployment value in a random
year with two party affiliations. For Decembers after 2002, the average
unemployment rate when a Democrat was president was 7.9833333.
Furthermore, the average unemployment rate when a Republican was
president was 5.5285714.

# Problem 2

Read and clean the Mr. Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  read_excel
- use reasonable variable names
- omit rows that do not include dumpster-specific data
- round the number of sports balls to the nearest integer and converts
  the result to an integer variable (using as.integer)

``` r
#readxl::read_excel("202409 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range ="A2:N586", na = c("NA", "", ".")) |>
mr_trash_wheel_df =
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",range = "A2:N586") |>
  janitor::clean_names() |>
  mutate(
    year = as.integer(year),
    homes_powered = weight_tons*500/30,
    sports_balls = as.integer(round(sports_balls)), 
    trash_wheel = "Mr. Trash Wheel",
    ) |> 
  drop_na(dumpster)
```

Read and clean Professor Trash Wheel dataset

``` r
professor_trash_wheel_df = 
  #read_excel("202409 Trash Wheel Collection Data.xlsx", 
  #           sheet = "Professor Trash Wheel",
  #          range = "A2:M120",
  #           na = c("NA", "", ".")) |> 
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Professor Trash Wheel",
             range = "A2:M120"
             ) |>
  janitor::clean_names() |> 
  mutate(
    trash_wheel = "Professor", 
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    ) |> 
  select(-dumpster)
```

Read and clean Gwynnda dataset

``` r
gwynnda_trash_wheel_df = 
  readxl::read_excel("202409 Trash Wheel Collection Data.xlsx", 
             sheet = "Gwynnda Trash Wheel",
             range = "A2:L265",
             na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |>
  mutate(
    trash_wheel = "Gwynnda",
    year = as.numeric(year),
    homes_powered = weight_tons * 500 / 30
    )
```

Combine this with the Mr. Trash Wheel dataset to produce a single tidy
dataset.

``` r
trash_wheel_whole_df = bind_rows(mr_trash_wheel_df, professor_trash_wheel_df, gwynnda_trash_wheel_df) |>
relocate(trash_wheel)
```

Write a paragraph about these data - you are encouraged to use inline
R. - Be sure to note the number of observations in the resulting
dataset, and give examples of key variables. - For available data, what
was the total weight of trash collected by Professor Trash Wheel? - What
was the total number of cigarette butts collected by Gwynnda in June of
2022?

- `mr_trash_wheel_df` contains 584 rows and 15 columns of data.
- `professor_trash_wheel_df` contains 118 rows and 13 columns of data.
- `gwynnda_trash_wheel_df` contains 263 rows and 13 columns of data.
- The final data set `trash_wheel_whole_df` contains 965 rows and 15
  columns of data. The variables are trash_wheel, dumpster, month, year,
  date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
  cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls,
  homes_powered.
- The total weight of trash collected by Professor Trash Wheel is
  246.74.
- The total number of cigarette butts collected by Gwynnda in June of
  2022 is 18120.

# Problem 3

Zillow Observed Rent Index (ZORI) in New York City between January 2015
and August 2024.

Firstsly ,we load the dataset.

``` r
zip_codes_df = read_csv("zillow_data/Zip Codes.csv")
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
zori_df = read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv")
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

- create a single, well-organized dataset with all the information
  contained in these data files.
- To that end: import, clean, tidy, and otherwise wrangle each of these
  datasets
- check for completeness and correctness across datasets (e.g. by
  viewing individual datasets and monitoring warning messages).
- merge to create a single, final dataset
- organize this so that variables and observations are in meaningful
  orders.

We first do data cleaning about zip code datasets.

``` r
zip_codes_df = 
  read_csv("zillow_data/Zip Codes.csv") |>
  rename(
    county = County,
    state_fips = "State FIPS",
    county_code = "County Code",
    county_fips = "County FIPS",
    zip_code = ZipCode,
    file_date = "File Date",
    neighborhood = Neighborhood
  ) |>
  drop_na(neighborhood) |>
  filter(neighborhood != "NA") |>
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y"))
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Next, we do data cleaning on zillow rent price dataset.

``` r
zillow_rent_df = 
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv") |>
  rename(
     zip_code = "RegionName",
     region_id = "RegionID",
     size_rank = "SizeRank",
     region_type = "RegionType",
     state_name = "StateName",
     state = "State",
     city = "City",
     metro = "Metro",
     county_name = "CountyName"
  ) |>
  select(zip_code, everything()) |>
  pivot_longer(
    cols = starts_with("20"),
    names_to = "date",
    values_to = "rent"
  ) |>
  drop_na(rent)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Moreover, we merge them together by using left join methods and drop
unimportant and repeated variables.

``` r
merged_data_df = 
  left_join(zillow_rent_df, zip_codes_df, by = "zip_code") |>
  select(-county, -state) |>
  relocate(zip_code, county_name, neighborhood, rent)
```

    ## Warning in left_join(zillow_rent_df, zip_codes_df, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 2759 of `x` matches multiple rows in `y`.
    ## ℹ Row 131 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

We will use two ways to check the the ZIP codes appear in the ZIP code
dataset but not in the Zillow Rental Price dataset.

Possible reasons for exclusion from Zillow:

- Low population density or limited rental activity: Many of the missing
  ZIP codes correspond to areas with smaller populations or fewer rental
  units like Rockaways. Zillow may not have enough transactions to
  generate reliable rental price estimates.

- Non-residential areas: Some ZIP codes may contain industrial zones,
  commercial areas, parks, or other non-residential regions, where
  typical rental data is unavailable.

- Data privacy : Zillow might exclude ZIP codes with very few rental
  listings to protect the privacy of landlords and tenants, or to avoid
  publishing unreliable estimates.

Take an example of ZIP code 10464, which is absent from Zillow’s rental
dataset. It may due to insufficient rental listings or low market
activity in that area. Furthermore, the region Rockaways we mention
aboved is absent from Zillow due to small populations.

``` r
difference_in_zipcodes_df = 
  anti_join(zip_codes_df, zillow_rent_df)
```

    ## Joining with `by = join_by(zip_code)`

``` r
difference_in_zipcodes_df
```

    ## # A tibble: 34 × 7
    ##    county   state_fips county_code county_fips zip_code file_date  neighborhood 
    ##    <chr>         <dbl> <chr>             <dbl>    <dbl> <date>     <chr>        
    ##  1 Bronx            36 005               36005    10464 2007-07-25 Southeast Br…
    ##  2 Bronx            36 005               36005    10474 2007-07-25 Hunts Point …
    ##  3 Bronx            36 005               36005    10475 2007-07-25 Northeast Br…
    ##  4 Kings            36 047               36047    11224 2007-07-25 Southern Bro…
    ##  5 Kings            36 047               36047    11239 2007-07-25 Canarsie and…
    ##  6 New York         36 061               36061    10020 2007-07-25 Chelsea and …
    ##  7 Queens           36 081               36081    11004 2007-07-25 Southeast Qu…
    ##  8 Queens           36 081               36081    11005 2007-07-25 Southeast Qu…
    ##  9 Queens           36 081               36081    11359 2007-07-25 North Queens 
    ## 10 Queens           36 081               36081    11362 2007-07-25 Northeast Qu…
    ## # ℹ 24 more rows

``` r
zip_not_in_zillow =
  zip_codes_df |>
  filter(!zip_code %in% zillow_rent_df$zip_code)
zip_not_in_zillow
```

    ## # A tibble: 34 × 7
    ##    county   state_fips county_code county_fips zip_code file_date  neighborhood 
    ##    <chr>         <dbl> <chr>             <dbl>    <dbl> <date>     <chr>        
    ##  1 Bronx            36 005               36005    10464 2007-07-25 Southeast Br…
    ##  2 Bronx            36 005               36005    10474 2007-07-25 Hunts Point …
    ##  3 Bronx            36 005               36005    10475 2007-07-25 Northeast Br…
    ##  4 Kings            36 047               36047    11224 2007-07-25 Southern Bro…
    ##  5 Kings            36 047               36047    11239 2007-07-25 Canarsie and…
    ##  6 New York         36 061               36061    10020 2007-07-25 Chelsea and …
    ##  7 Queens           36 081               36081    11004 2007-07-25 Southeast Qu…
    ##  8 Queens           36 081               36081    11005 2007-07-25 Southeast Qu…
    ##  9 Queens           36 081               36081    11359 2007-07-25 North Queens 
    ## 10 Queens           36 081               36081    11362 2007-07-25 Northeast Qu…
    ## # ℹ 24 more rows

The result shows the same output.

- Briefly describe the resulting tidy dataset.
- How many total observations exist? How many unique ZIP codes are
  included
- How many unique neighborhoods

The resulting tidy dataset `merged_data_df` combines information from
the Zillow rental price dataset and the ZIP code dataset for New York
City. It is organized in a long format, where each row represents the
observed rent for a given ZIP code, neighborhood, and month.

- The dataset contains a total of 10677 observations.  
- There are 149 unique ZIP codes included.  
- The dataset covers 43 unique neighborhoods across all boroughs.
- Date range of the rent observations: from to -

Each observation includes the following variables:

- `zip_code`: the ZIP code of the area  
- `county_name`: the county name corresponding to the ZIP code  
- `neighborhood`: the neighborhood name associated with the ZIP code  
- `month`: the month of the rent observation  
- `rent`: the Zillow Observed Rent Index (ZORI) for the corresponding
  month and ZIP code

Missing values in `rent` or `neighborhood` have been removed to ensure
completeness. The variables are organized in a meaningful order, with
`zip_code`, `county_name`, and `neighborhood` first, followed by rent
and month information.

Rental prices fluctuated dramatically during the COVID-19 pandemic. -
For all available ZIP codes, compare rental prices in January 2021 to
prices in January 2020. - Make a table that shows the 10 ZIP codes
(along with the borough and neighborhood) with largest drop in price
from January 2020 to 2021. - Comment.

First, we filtered data from merged_data_df to include only January 2020
and January 2021 records, extracting key variables: ZIP code, borough
(county), neighborhood, year, and rent. We then removed duplicate
entries to ensure each combination had one unique rent value.

Next, we restructured the data to have separate columns for 2020 and
2021 rents, calculated the price change (drop_price = 2021 rent - 2020
rent), and removed entries with missing data.

``` r
rent_jan = 
  merged_data_df |>
  mutate(
    date = as.Date(date, format = "%Y-%m-%d"),
    year = year(date),
    month = month(date),
    day = day(date)
    ) |>
  filter(month == 1 & (year == 2020 | year == 2021)) |>
  select(zip_code, county_name, neighborhood, year, rent)
```

``` r
rent_diff = 
  rent_jan |>
  distinct() |>
  pivot_wider(
    id_cols = c(zip_code, county_name, neighborhood), 
    names_from = year,                                 
    values_from = rent,                                
    names_prefix = "rent_") |>
  mutate(drop_price = rent_2021 - rent_2020) |>
  drop_na() |>
  select(county_name, zip_code, neighborhood, drop_price)
```

We create a table about top 10 drop with appropriate caption names

``` r
top10_drop =
  rent_diff |>
  arrange(drop_price) |>
  slice_head(n = 10) |>
  rename(
    "Borough" = county_name,      
    "ZIP Code" = zip_code,        
    "Neighborhood" = neighborhood, 
    "Price Drop (2020-2021)" = drop_price  
  )
```

``` r
knitr::kable(
  top10_drop,
  caption = "Top 10 largest drop in price from January 2020 to 2021",
  align = "lccc"  
)
```

| Borough | ZIP Code | Neighborhood | Price Drop (2020-2021) |
|:---|:--:|:--:|:--:|
| New York County | 10007 | Lower Manhattan | -912.5966 |
| New York County | 10009 | Lower East Side | -714.2550 |
| New York County | 10016 | Gramercy Park and Murray Hill | -711.7045 |
| New York County | 10001 | Chelsea and Clinton | -710.4499 |
| New York County | 10002 | Lower East Side | -710.3028 |
| New York County | 10004 | Lower Manhattan | -705.9608 |
| New York County | 10038 | Lower Manhattan | -697.5853 |
| New York County | 10012 | Greenwich Village and Soho | -686.2218 |
| New York County | 10010 | Gramercy Park and Murray Hill | -684.9304 |
| New York County | 10003 | Lower East Side | -672.5404 |

Top 10 largest drop in price from January 2020 to 2021

Comments:

The table shows that all listed ZIP codes in New York County saw a
significant drop in rental prices from January 2020 to January 2021,
with decreases between about \$672 and \$913. The biggest decline
happened in Lower Manhattan (ZIP 10007), which indicates the strong
effect of the COVID-19 pandemic on this sought-after area.

All the affected ZIP codes are in Manhattan, including neighborhoods
like Lower East Side, Gramercy Park, Chelsea, and Lower Manhattan
itself. These central, high-rent areas usually attract a lot of
residential and commercial interest, making them especially vulnerable
to changes in population movement and economic activity.

The declines likely come from lower demand due to remote work, people
moving away, and less short-term rental activity during the pandemic.
This data shows that Manhattan’s main rental market was hit hardest,
offering valuable insights for investors, property managers, and
policymakers looking at the short-term impacts of the pandemic on urban
housing markets.
